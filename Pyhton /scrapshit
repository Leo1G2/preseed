import re
import requests
from bs4 import BeautifulSoup

base_url = "https://www.barreau-montpellier.com/fr/annuaire/tableau"
page_number = 1
emails_found = False

while True:
    # Construction de l'URL pour chaque page
    url = base_url if page_number == 1 else f"{base_url}/page-{page_number}"
    response = requests.get(url)
    
    if response.status_code != 200:
        print(f"Impossible de récupérer la page {page_number}. Code de statut : {response.status_code}")
        break

    # Parse le contenu de la page avec BeautifulSoup
    soup = BeautifulSoup(response.content, 'html.parser')
    page_text = soup.get_text()
    
    # Extraction des emails sur la page actuelle
    emails = re.findall(r'\b[A-Za-z0-9.%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', page_text)
    
    if emails:
        emails_found = True
        print(f"Emails trouvés sur la page {page_number} :")
        for idx, email in enumerate(emails, start=1):
            print(f"Email {idx}: {email}")
    else:
        print(f"Aucun email trouvé sur la page {page_number}.")
    
    # Vérifie si un lien vers la page suivante existe
    next_page_link = soup.find('a', text=str(page_number + 1))
    
    if not next_page_link:  # Arrête la boucle si pas de page suivante
        print("Aucune page suivante trouvée.")
        break

    # Incrémente pour la page suivante
    page_number += 1

if not emails_found:
    print("Aucun email trouvé sur toutes les pages.")
